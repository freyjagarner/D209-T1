{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560e30a6-2943-482e-bf47-30a2be345bf2",
   "metadata": {},
   "source": [
    "#### Chelsey De Dios\n",
    "\n",
    "# D209 Task 1 Classification Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe9ff1-7879-445f-9874-82712cb103bb",
   "metadata": {},
   "source": [
    "## Part I: Research Question\n",
    "\n",
    "### A.  Describe the purpose of this data mining report by doing the following:\n",
    "\n",
    "#### 1.  Propose one question relevant to a real-world organizational situation that you will answer using one of the following classification methods:\n",
    "\n",
    "* k-nearest neighbor (KNN)\n",
    "\n",
    "* Naive Bayes\n",
    "\n",
    "The question we will be posing is whether we can correctly classify customer's as either churn or no churn (leaving the company or not) based on other data about the customer using k-nearest neighbors to classify customers.\n",
    "\n",
    "#### 2.  Define one goal of the data analysis. Ensure that your goal is reasonable within the scope of the scenario and is represented in the available data.\n",
    "\n",
    "One goal of this analysis will be to use k-nearest neighbors to correctly classify most customers as either churning or not.\n",
    " \n",
    "\n",
    "## Part II: Method Justification\n",
    "\n",
    "### B.  Explain the reasons for your chosen classification method from part A1 by doing the following:\n",
    "\n",
    "#### 1.  Explain how the classification method you chose analyzes the selected data set. Include expected outcomes.\n",
    "\n",
    "K-nearest neighbors starts with a certain number of known categories, in this case Yes and No for churn and then when given an unknown value, analyzes the value to see whether it falls closely to other previously classified data points, and classifies the new data point based on how closely it comes to similar datapoints that are already classified, which are the nearest 'neighbors'. The algorithm chooses the category based on how many nearest neighbors that you pass through the algorithm. For example, if you pass 3 neighbors, it will plot the datapoint, and find the 3 nearest data points the new data comes close to. Then it will classify it based on which of those neighbors and what number of those neighbors are closer.\n",
    "\n",
    "The expected outcome would be for the classifier to be able to identify a new customer entry as being either a churn or no churn customer based on it's proximity to other similar customers.\n",
    "\n",
    "#### 2.  Summarize one assumption of the chosen classification method.\n",
    "\n",
    "K-nearest neighbors assumes that, in the categories chosen, similar data points are plotted somewhat tightly together so that the algorithm can figure out the categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b152d5-2422-4652-836d-f488c1d40d06",
   "metadata": {},
   "source": [
    "#### 3.  List the packages or libraries you have chosen for Python or R, and justify how each item on the list supports the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da82dcc-9d3a-47dd-8444-cce840528f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023d589-0afd-4faf-9f97-a3b421207662",
   "metadata": {},
   "source": [
    "a. Pandas allows us to work with the data through dataframes which allow for various simple data manipulations.\n",
    "\n",
    "b. Numpy allows us to work with arrays of data, and is needed for some Pandas manipulations.\n",
    "\n",
    "c. seaborn and matplotlib pyplot allow us to create visualizations easily so we can look at our data graphically.\n",
    "\n",
    "d. sklearn allows us to use their machine learning algorithms in a black box manner, and to transform our data to work with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617b3f4f-d322-4929-861b-8b07bc4d1e0c",
   "metadata": {},
   "source": [
    "## Part III: Data Preparation\n",
    "\n",
    "### C.  Perform data preparation for the chosen data set by doing the following:\n",
    "\n",
    "#### 1.  Describe one data preprocessing goal relevant to the classification method from part A1.\n",
    "\n",
    "Data will be encoded into dummy variables in order to be numeric which allows it to work with the algorithm.\n",
    "\n",
    "#### 2.  Identify the initial data set variables that you will use to perform the analysis for the classification question from part A1, and classify each variable as continuous or categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249f77b-093f-4bd0-8246-3344650fd1e3",
   "metadata": {},
   "source": [
    "This is performed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09c0d6-5ff9-4981-a117-b18e27c3c7d9",
   "metadata": {},
   "source": [
    "#### 3.  Explain each of the steps used to prepare the data for the analysis. Identify the code segment for each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3011a85-0c8f-449e-98ad-c15cce1abc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from csv\n",
    "df = pd.read_csv('churn_clean.csv')\n",
    "\n",
    "# set it so we can see all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4dc82-2af7-4d2d-9909-8372c122dc2a",
   "metadata": {},
   "source": [
    "##### a. Change Column Names\n",
    "\n",
    "It is useful to change the column names in order to better identify non-descriptive variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231574ea-936b-4239-aff3-7b280ace12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of current column names mapping to desired column names\n",
    "survey_dict = {'Item1':'timely_responses', \n",
    "               'Item2':'timely_fixes', \n",
    "               'Item3':'timely_replacements', \n",
    "               'Item4':'reliability', \n",
    "               'Item5':'options', \n",
    "               'Item6':'respectful_response', \n",
    "               'Item7':'courteous_exchange', \n",
    "               'Item8':'evidence_of_active_listening'}\n",
    "\n",
    "# rename the column names based on survey_dict\n",
    "df = df.rename(columns=survey_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035374f4-940f-46b0-8f0b-b835d861f07f",
   "metadata": {},
   "source": [
    "##### b. Change Data Types\n",
    "\n",
    "Now we will change the datatypes of our columns by passing a dictionary to df.astype mapping our column names to their new typing. We will do this because models will recognize the variable's datatype and deal with data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded38168-4e2c-4722-9d50-5e00e45f1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dataframe columns to more appropriate data types\n",
    "df = df.astype({'Population':int, \n",
    "                'Area':'category',\n",
    "                'Children':int, \n",
    "                'Age':int,\n",
    "                'Income':float, \n",
    "                'Marital':'category', \n",
    "                'Gender':'category', \n",
    "                'Churn':'category',\n",
    "                'Outage_sec_perweek':float, \n",
    "                'Email':int, \n",
    "                'Contacts':int, \n",
    "                'Yearly_equip_failure':int,\n",
    "                'Techie':'category', \n",
    "                'Contract':'category', \n",
    "                'Port_modem':'category', \n",
    "                'Tablet':'category', \n",
    "                'InternetService':'category',\n",
    "                'Phone':'category', \n",
    "                'Multiple':'category', \n",
    "                'OnlineSecurity':'category', \n",
    "                'OnlineBackup':'category',\n",
    "                'DeviceProtection':'category', \n",
    "                'TechSupport':'category', \n",
    "                'StreamingTV':'category', \n",
    "                'StreamingMovies':'category',\n",
    "                'PaperlessBilling':'category', \n",
    "                'PaymentMethod':'category', \n",
    "                'Tenure':float, \n",
    "                'MonthlyCharge':float,\n",
    "                'Bandwidth_GB_Year':float, \n",
    "                'timely_responses':int, \n",
    "                'timely_fixes':int, \n",
    "                'timely_replacements':int, \n",
    "                'reliability':int, \n",
    "                'options':int,\n",
    "                'respectful_response':int, \n",
    "                'courteous_exchange':int, \n",
    "                'evidence_of_active_listening':int}, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661058bf-8203-42d6-ada7-f83526b255f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the dataframe to relevant variables\n",
    "df = df[['Population', 'Area', 'Age', 'Gender', 'Children', 'Marital', 'Income',\n",
    "         'Outage_sec_perweek', 'Email', 'Contacts', 'Yearly_equip_failure',\n",
    "         'Techie', 'Contract', 'Port_modem', 'Tablet', 'InternetService',\n",
    "         'Phone', 'Multiple', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "         'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', \n",
    "         'PaymentMethod', 'Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year',\n",
    "         'timely_responses', 'timely_fixes', 'timely_replacements', 'reliability',\n",
    "         'options', 'respectful_response', 'courteous_exchange', \n",
    "         'evidence_of_active_listening', 'Churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff5758e-fbcd-41ae-8159-1a39b88a9251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable and DataType\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Children</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outage_sec_perweek</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contacts</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yearly_equip_failure</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Techie</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Port_modem</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tablet</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternetService</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnlineBackup</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceProtection</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TechSupport</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamingTV</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreamingMovies</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaymentMethod</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyCharge</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bandwidth_GB_Year</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timely_responses</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timely_fixes</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timely_replacements</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reliability</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respectful_response</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>courteous_exchange</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence_of_active_listening</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DataType\n",
       "Population                        numeric\n",
       "Area                          categorical\n",
       "Age                               numeric\n",
       "Gender                        categorical\n",
       "Children                          numeric\n",
       "Marital                       categorical\n",
       "Income                        categorical\n",
       "Outage_sec_perweek            categorical\n",
       "Email                             numeric\n",
       "Contacts                          numeric\n",
       "Yearly_equip_failure              numeric\n",
       "Techie                        categorical\n",
       "Contract                      categorical\n",
       "Port_modem                    categorical\n",
       "Tablet                        categorical\n",
       "InternetService               categorical\n",
       "Phone                         categorical\n",
       "Multiple                      categorical\n",
       "OnlineSecurity                categorical\n",
       "OnlineBackup                  categorical\n",
       "DeviceProtection              categorical\n",
       "TechSupport                   categorical\n",
       "StreamingTV                   categorical\n",
       "StreamingMovies               categorical\n",
       "PaperlessBilling              categorical\n",
       "PaymentMethod                 categorical\n",
       "Tenure                        categorical\n",
       "MonthlyCharge                 categorical\n",
       "Bandwidth_GB_Year             categorical\n",
       "timely_responses                  numeric\n",
       "timely_fixes                      numeric\n",
       "timely_replacements               numeric\n",
       "reliability                       numeric\n",
       "options                           numeric\n",
       "respectful_response               numeric\n",
       "courteous_exchange                numeric\n",
       "evidence_of_active_listening      numeric\n",
       "Churn                         categorical"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of variables with classification of categorical or numeric\n",
    "print('Variable and DataType')\n",
    "types = pd.DataFrame(['numeric' if df[i].dtypes == (int or float) \n",
    "                      else 'categorical' for i in df.columns], df.columns, columns=['DataType'])\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2461100-561e-499a-badd-161d3bca30ee",
   "metadata": {},
   "source": [
    "Above all of the variables used in this analysis and their datatypes are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233d551-109a-402f-9504-2ace5b825cab",
   "metadata": {},
   "source": [
    "##### c. Get dummy variables for categorical data\n",
    "\n",
    "Here we will first replace all binary values in variables with 1's and 0's. Then, using pd.getdummies we will get dummy variables/one hot encoded variables to make our categorical data numeric in order to work with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aecedf3-23e1-40d2-aad0-faea9f83f180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843ee130-dd69-41e0-8edc-29ff6499f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of columns with churn at the end\n",
    "ordered_cols = [i for i in df.columns if i != 'Churn'] + ['Churn']\n",
    "\n",
    "# reorder columns to get target variable last\n",
    "ordered_df = df[ordered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcd6807-e024-48ba-82c1-5777ead8b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all Yes/No values with 1 and 0 in all columns except target\n",
    "dummy_df = ordered_df[ordered_df.columns[:-1]].replace({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbb0fdb-a037-43d2-9d2d-36b8cc2eaec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy values for dataframe\n",
    "dummy_df = pd.get_dummies(dummy_df)\n",
    "\n",
    "# append churn to dummy_df\n",
    "dummy_df['Churn'] = ordered_df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fa7b519-1a0f-4608-9765-a41fbbb11936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric columns list\n",
    "num_cols = set(df._get_numeric_data().columns)\n",
    "\n",
    "# get categorical column list and remove target\n",
    "cat_cols = set(df.columns) - num_cols\n",
    "cat_cols.remove('Churn')\n",
    "\n",
    "# get categorical values in dummy_df\n",
    "dummy_cats = list(set(dummy_df.columns) - num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c63f772c-feb5-4941-a303-483339114b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical data back to category\n",
    "dummy_df[dummy_cats] = dummy_df[dummy_cats].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84511197-6ab2-49c4-acbc-1481aac8f075",
   "metadata": {},
   "source": [
    "##### d. Scale Numerical Data\n",
    "\n",
    "Now we will use sklearn's StandardScaler to scale our numeric data so nothing is improperly weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75514f9f-79df-4691-9c92-42c1b1baf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler numeric data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "dummy_df[list(num_cols)] = scaler.fit_transform(dummy_df[list(num_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620eacce-7c2d-48d6-b616-b5911f93f927",
   "metadata": {},
   "source": [
    "##### e. Reorder Columns for Target Variable\n",
    "\n",
    "Next we will reorder our columns to put our target variable 'Churn' at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c0e407f-ea49-47d4-9048-110eaa3c5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order columns to get target variable to the end\n",
    "ordered_cols = [i for i in dummy_df.columns if i != 'Churn'] + ['Churn']\n",
    "dummy_df = dummy_df[ordered_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e20c5-111d-44ba-9328-29403cb6dbf2",
   "metadata": {},
   "source": [
    "#### 4.  Provide a copy of the cleaned data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7de5db7-f721-4541-9a0d-c59258fc214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export cleaned data to csv\n",
    "df.to_csv('t1_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac8808-c9cb-4c10-ae07-fc285cd0babd",
   "metadata": {},
   "source": [
    "## Part IV: Analysis\n",
    "\n",
    "### D.  Perform the data analysis and report on the results by doing the following:\n",
    "\n",
    "#### 1.  Split the data into training and test data sets and provide the file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c5df858-cc5f-4dca-9358-6d856b1fb4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train/test sets\n",
    "train, test = train_test_split(dummy_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b42ed4-1555-41c6-8446-3a005c53991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export training data to csv\n",
    "train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67db5aae-8cda-4635-bf13-c8ecf93e90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export test data to csv\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3785f5e2-2b8d-4dc5-8b45-2ba4101bd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into explanatory and target variables\n",
    "X_train, y_train, X_test, y_test = train.iloc[:,0:-1], train.iloc[:,-1:], test.iloc[:,0:-1], test.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35b9b9-d6a9-4eb6-a480-945593f82beb",
   "metadata": {},
   "source": [
    "#### 2.  Describe the analysis technique you used to appropriately analyze the data. Include screenshots of the intermediate calculations you performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ba247e1-402a-4706-8eaf-f28da87eb817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8123333333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit data to algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# get prediction for x test\n",
    "pred = neigh.predict(X_test)\n",
    "\n",
    "# get accuracy score\n",
    "neigh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08931203-6bef-4ccb-921b-1403c835c56c",
   "metadata": {},
   "source": [
    "The score for this classification is around .812, which is the accuracy score for our test set. The accuracy is fraction of correct predictions vs the total predictions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fd2f9ad-ad72-43b9-8b22-9af919e5d2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303101561606978"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "neigh_prob = neigh.predict_proba(X_test)\n",
    "roc_auc_score(y_test, neigh_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4b490-e20e-454d-acb7-23137a5cbaec",
   "metadata": {},
   "source": [
    "Our ROC AUC score above is around .83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f04338b7-4a29-406b-a686-c8842228751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn_Yes_True</th>\n",
       "      <th>Churn_No_True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Churn_Yes_Pred</th>\n",
       "      <td>1928</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn_No_Pred</th>\n",
       "      <td>335</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Churn_Yes_True  Churn_No_True\n",
       "                                             \n",
       "Churn_Yes_Pred            1928            228\n",
       "Churn_No_Pred              335            509"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "con_matrix = pd.DataFrame(confusion_matrix(y_test, pred), columns=['Churn_Yes_True', 'Churn_No_True'])\n",
    "con_matrix[''] = ['Churn_Yes_Pred', 'Churn_No_Pred']\n",
    "con_matrix.set_index('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4160353f-e4c1-49ab-8598-a96ffe0bd974",
   "metadata": {},
   "source": [
    "In the above confusion matrix we can see the results of our classification with 1928 true positives, 228 false positives, 335 false negatives and 509 false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b5217-ad99-4bea-a1ad-3878c9f9864b",
   "metadata": {},
   "source": [
    "#### 3.  Provide the code used to perform the classification analysis from part D2.\n",
    "\n",
    "The code for the classification is above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f1918-102d-4d86-9263-ce888493c840",
   "metadata": {},
   "source": [
    "### Part V: Data Summary and Implications\n",
    "\n",
    "### E.  Summarize your data analysis by doing the following:\n",
    "\n",
    "#### 1.  Explain the accuracy and the area under the curve (AUC) of your classification model.\n",
    "\n",
    "The accuracy score for the knn classification was just over .812. The accuracy is the fraction of correct predictions vs the total predictions for the classification model.\n",
    "\n",
    "The ROC gives us the plotted true positive to false positive rate for every possible classification threshold. The AUC gives us the area under the curve of the ROC graph, which tells us how often our model provides correct positive or negative classifications. Our score for our ROC AUC is .83, which means 83% of cases were correctly identified.\n",
    "\n",
    "#### 2.  Discuss the results and implications of your classification analysis.\n",
    "\n",
    "The results of this analysis suggest that it is possible to classify customers as churning or not based on the inputs from this data around with over 80% accuracy, making this a potentially useful model. This also suggests that this data is useful for predicting customer churn.\n",
    "\n",
    "#### 3.  Discuss one limitation of your data analysis.\n",
    "\n",
    "One limitation of this analysis is that there are only 10,000 entries for customer data, and we do not know the true population size of customers to compare and decide if this model it truly as valuable as the scoring suggests.\n",
    "\n",
    "#### 4.  Recommend a course of action for the real-world organizational situation from part A1 based on your results and implications discussed in part E2.\n",
    "\n",
    "It would be good to attempt to use this model to identify customers that have not yet churned, but are classified as those who would churn in this model. After these customers are identified, it would be beneficial to focus on those customers whom are classified as churning for retention.\n",
    " \n",
    "\n",
    "## Part VI: Demonstration\n",
    "\n",
    "### F.  Provide a Panopto video recording that includes a demonstration of the functionality of the code used for the analysis and a summary of the programming environment.\n",
    "\n",
    "https://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=3757504a-78d6-49bf-98bf-addb016dfeee\n",
    "\n",
    "### G.  Record the web sources used to acquire data or segments of third-party code to support the analysis. Ensure the web sources are reliable.\n",
    "\n",
    "N/A\n",
    "\n",
    "### H.  Acknowledge sources, using in-text citations and references, for content that is quoted, paraphrased, or summarized.\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7c86a-c5e8-491e-bedf-94834b600a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
